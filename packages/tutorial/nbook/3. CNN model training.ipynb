{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f990c261-e52b-4b32-aa3d-003be634d651",
   "metadata": {},
   "source": [
    "# CNN training example\n",
    "\n",
    "This notebook illustrates how to use EDIT pipeline to train a simple CNN model on the ERA5 lowres dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629b9551-8ff2-46d2-bc70-db1a84a6192e",
   "metadata": {},
   "source": [
    "Make sure to set the `ERA5LOWRES` environment variable to make the ERA5 low-resolution archive foundable on your system.\n",
    "Modify the following cell as follows:\n",
    "\n",
    "- for NCI\n",
    "\n",
    "```\n",
    "%env ERA5LOWRES=/g/data/wb00/NCI-Weatherbench/5.625deg\n",
    "```\n",
    "\n",
    "- for NIWA\n",
    "\n",
    "```\n",
    "%env ERA5LOWRES=/nesi/nobackup/niwa00004/riom/weatherbench/5.625deg\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613f5e9f-0378-4c74-93ee-c49083bee302",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env ERA5LOWRES=/nesi/nobackup/niwa00004/riom/weatherbench/5.625deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd1e8b6-acc3-4074-92db-536c0e8ea112",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from lightning import Trainer, LightningModule\n",
    "\n",
    "import edit.data\n",
    "import edit.tutorial  # NOQA\n",
    "import edit.pipeline\n",
    "import edit.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cd2afc-fdc1-418c-a4a0-59d8cd080de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = \"cnn_training\"\n",
    "cache_folder = None\n",
    "\n",
    "train_start = \"2015-01-01T00\"\n",
    "train_end = \"2015-01-12T00\"  # \"2015-12-31T00\"\n",
    "val_start = \"2017-01-01T00\"\n",
    "val_end = \"2017-01-12T00\"\n",
    "\n",
    "n_samples = 200\n",
    "batch_size = 1\n",
    "n_workers = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d411691-1c6f-4feb-902f-24bc79b00d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = Path(train_folder)\n",
    "train_folder.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09783db6-2e4e-4e57-8a66-6121a781e737",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_preparation = edit.pipeline.Pipeline(\n",
    "    edit.data.archive.era5lowres([\"u\", \"v\", \"geopotential\", \"vorticity\"]),\n",
    "    edit.pipeline.operations.xarray.Sort(\n",
    "        [\"msl\", \"10u\", \"10v\", \"2t\", \"geopotential\", \"vorticity\"]\n",
    "    ),\n",
    "    edit.data.transforms.coordinates.standard_longitude(type=\"0-360\"),\n",
    "    edit.pipeline.operations.xarray.reshape.CoordinateFlatten(\"level\"),\n",
    "    # retrieve previous/next samples, dt = 1H\n",
    "    edit.pipeline.modifications.TemporalRetrieval(\n",
    "        concat=True, samples=((-1, 1), (1, 1, 1))\n",
    "    ),\n",
    "    edit.pipeline.operations.xarray.conversion.ToNumpy(),\n",
    "    edit.pipeline.operations.numpy.reshape.Rearrange(\"c t h w -> t c h w\"),\n",
    "    edit.pipeline.operations.numpy.reshape.Squish(axis=0),\n",
    ")\n",
    "data_preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4c4ff2-78ac-4ab8-bce2-ffbcadb202e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = data_preparation[train_start]\n",
    "print(len(sample))\n",
    "print(sample[0].shape)\n",
    "print(sample[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c4baca-afe0-4450-9371-7aa57fb9e39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = edit.pipeline.iterators.DateRange(train_start, train_end, interval=\"1h\")\n",
    "train_split = train_split.randomise(seed=42)\n",
    "val_split = edit.pipeline.iterators.DateRange(val_start, val_end, interval=\"1h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927ca606-6031-44b4-a646-4b88528f3f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8465ac6f-4c01-4f6e-ae71-bf399d7fb764",
   "metadata": {},
   "source": [
    "Let's precompute approximate mean and standard deviation using only few random samples, to rescale the input/output data to a reasonable range for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b69b1c-780f-4890-bf00-8409026205bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.stack([data_preparation[train_split[i]][0] for i in range(n_samples)])\n",
    "mean_approx = np.mean(samples, axis=0)\n",
    "std_approx = np.std(samples, axis=0)\n",
    "\n",
    "mean_path = train_folder / \"mean.npy\"\n",
    "std_path = train_folder / \"std.npy\"\n",
    "np.save(mean_path, mean_approx)\n",
    "np.save(std_path, std_approx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebf6ab9-1b81-42f0-b7f7-073491114bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "normaliser = edit.pipeline.operations.numpy.normalisation.Deviation(\n",
    "    mean=mean_path, deviation=std_path\n",
    ")\n",
    "data_preparation_normed = edit.pipeline.Pipeline(data_preparation, normaliser)\n",
    "\n",
    "if cache_folder is not None:\n",
    "    data_preparation_normed = edit.pipeline.Pipeline(\n",
    "        data_preparation_normed,\n",
    "        edit.pipeline.modifications.Cache(\n",
    "            cache_folder, pattern_kwargs={'extension': 'npy'}\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d6e689-f5c7-4b6b-a88e-d7d12c8997fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preparation_normed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615389bf-2e4d-4cac-abe0-06637d699792",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = edit.training.data.lightning.PipelineLightningDataModule(\n",
    "    data_preparation_normed,\n",
    "    train_split=train_split,\n",
    "    valid_split=val_split,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=n_workers,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54e16c5-dfe4-4c4b-bea7-ab7646591b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1a4965-b224-472f-9675-4c17f83f548f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CNN(LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        n_features: int,\n",
    "        layer_sizes: list[int],\n",
    "        dropout: float,\n",
    "        learning_rate: float,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        layer_sizes = (n_features,) + tuple(layer_sizes)\n",
    "        layers = []\n",
    "        for chan_in, chan_out in zip(layer_sizes[:-1], layer_sizes[1:]):\n",
    "            layers.extend(\n",
    "                [\n",
    "                    nn.Conv2d(chan_in, chan_out, kernel_size=3, stride=1, padding=1),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Dropout(p=dropout),\n",
    "                ]\n",
    "            )\n",
    "        layers.append(\n",
    "            nn.Conv2d(layer_sizes[-1], n_features, kernel_size=3, stride=1, padding=1)\n",
    "        )\n",
    "        self.cnn = nn.Sequential(*layers)\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "        self.loss_function = F.l1_loss\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.cnn(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs, targets = batch\n",
    "        outputs = self(inputs)\n",
    "        loss = self.loss_function(outputs, targets)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inputs, targets = batch\n",
    "        outputs = self(inputs)\n",
    "        loss = self.loss_function(outputs, targets)\n",
    "        self.log(\"val_loss\", loss)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return {\"optimizer\": optimizer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9493902-8c1e-40bd-b186-621b56aca9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = data_preparation_normed[train_start][0].shape[-3]\n",
    "model = CNN(\n",
    "    n_features=n_features, layer_sizes=[64, 64], dropout=0.6, learning_rate=1e-5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fa9f5a-b2b1-4952-a066-831b66d28917",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51aa6230-b381-4c04-b231-9cf432148079",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a669c85a-15de-4fb6-a98f-d5185c3b565a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(max_epochs=1)\n",
    "trainer.fit(model, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419c27ad-71f6-4792-8150-3482020ecb84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EDIT-tutorial",
   "language": "python",
   "name": "edit-tutorial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
